<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="URAvatar: Universal Relightable Gaussian Codec Avatars">
  <meta name="keywords" content="Avatars from phone scan, Gaussian Splatting, Relighting">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>URAvatar: Universal Relightable Gaussian Codec Avatars</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-3T8T6XDJY8"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-3T8T6XDJY8');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">URAvatar: Universal Relightable Gaussian Codec Avatars</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://junxuan-li.github.io/">Junxuan Li</a>,
              </span>
              <span class="author-block">
                <a href="https://sites.google.com/site/zjucaochen/home/">Chen Cao</a>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=x47jgTcAAAAJ&hl=en">Gabriel Schwartz</a>,
              </span>
              <span class="author-block">
                <a href="https://rawalkhirodkar.github.io/">Rawal Khirodkar</a>,
              </span>
              <br>
              <span class="author-block">
                <a href="https://richardt.name/">Christian Richardt</a>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=7aabHgsAAAAJ">Tomas Simon</a>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=Yd4KvooAAAAJ&hl=en">Yaser Sheikh</a>,
              </span>
              <span class="author-block">
                <a href="https://shunsukesaito.github.io/">Shunsuke Saito</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Codec Avatars Lab, Meta</span>
            </div>
            <br>
            <div class="columns is-centered">
              <div class="is-size-4 publication-venue">
                SIGGRAPH Asia 2024
              </div>
            </div>
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/****.****.pdf"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/****.****" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->

              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h2 class="subtitle has-text-centered">
          Our model is a high-fidelity <b>U</b>niversal prior for <b>R</b>elightable <b>Avatars</b>. 
        </h2>
        <h2 class="subtitle has-text-centered">
          You can create <span class="rgca">URAvatar</span> (<b>Your Avatar</b>) from  a phone scan. 
        </h2>
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/interpolate_video.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          Here is a video showing driving different relightable avatars with the target subject (left) expression. 
        </h2>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              In this work, we present <span class="rgca">URAvatar</span>, a new approach to creating photorealistic and relightable head avatars using a phone scan with unknown illumination. The reconstructed avatars can be animated and relit in real time with the global illumination of diverse environments. 
            </p>
            <p>
              Unlike existing approaches that estimate parametric reflectance parameters via inverse rendering, our approach directly models learnable radiance transfer that incorporates global light transport in an efficient manner for real-time rendering. However, learning such a complex light transport that can generalize across identities is non-trivial. A phone scan in a single environment lacks sufficient information to infer how the head would appear in general environments. To address this, we build a universal relightable avatar model represented by 3D Gaussians. We train on hundreds of high-quality multi-view human scans with controllable point lights. High-resolution geometric guidance further enhances the reconstruction accuracy and generalization. 
            </p>
            <p>
              Once trained, we finetune the pretrained model on a phone scan using inverse rendering to obtain a personalized relightable avatar. Our experiments establish the efficacy of our design, outperforming existing approaches while retaining real-time rendering capability.
            </p>
          </div>
        </div>
      </div>
      <div class="content has-text-centered">
        <img src="./static/images/overview.png">
      </div>
      <h2 class="subtitle has-text-centered">
        <span class="rgca">URAvatar</span> .  Our approach enables the creation of drivable and relightable photorealistic head avatars from a single phone scan (left). The reconstructed avatars can be driven consistently across identities under different illuminations in real time (right).
      </h2>
      <!--/ Abstract. -->

    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">

      <!-- Method. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Method Overview</h2>

          <div class="content has-text-justified">
            <p>
            We first employ a large relightable corpus of multi-view facial performances to train a cross-identity decoder that can generate volumetric avatar representations.
            Then given a single phone scan of an unseen identity, we reconstruct the head pose, geometry, and albedo texture, and fine-tune our pretrained relightable prior model.
            Our final model provides disentangled control over relighting, gaze and neck control.
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="./static/images/method_overview.png">
          </div>
    </div>
  </section>
          
  <section class="section">
    <div class="container is-max-desktop">
      <!-- Application. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">URAvatar from Phone Scan</h2>

          <!-- Re-rendering. -->
          <h3 class="subtitle has-text-centered">
            You can create <span class="rgca">URAvatar</span> using a phone scan in any natural environment, and then relight it in various lighting conditions.
          </h3>    
          <div class="content has-text-justified">
          </div>
          <div class="content has-text-centered">
            <video id="replay-video" controls muted preload playsinline width="75%">
              <source src="./static/videos/ica_1id_rotate_crop.mp4" type="video/mp4">
            </video>
          </div>
          <div class="content has-text-centered">
            <video id="replay-video" controls muted preload playsinline width="75%">
              <source src="./static/videos/ica_2id_rotate_crop.mp4" type="video/mp4">
            </video>
          </div>
          <!--/ Re-rendering. -->

          <!-- Re-rendering. -->
          <h3 class="title is-4">More from Phone Scan</h3>
          <div class="content has-text-justified">
          </div>
          <div class="content has-text-centered">
            <video id="replay-video" controls preload playsinline width="75%">
              <source src="./static/videos/ica-rotate-video_crop.mp4" type="video/mp4">
            </video>
          </div>
          <!--/ Re-rendering. -->
          <!-- Re-rendering. -->
          <h3 class="title is-4">Driving URAvatar with Target Expression</h3>
          <div class="content has-text-justified">
          </div>
          <div class="content has-text-centered">
            <video id="replay-video" controls preload playsinline width="75%">
              <source src="./static/videos/ica-driving-video_crop.mp4" type="video/mp4">
            </video>
          </div>
          <!--/ Re-rendering. -->
        </div>
      </div>
      <!--/ Animation. -->
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>

      <pre><code>
        @article{li2024uravatar,
          author = {Junxuan Li and Chen Cao and Gabriel Schwartz and Rawal Khirodkar and Christian Richardt and Tomas Simon and Yaser Sheikh and Shunsuke Saito},
          title = {URAvatar: Universal Relightable Gaussian Codec Avatars}, 
          journal = {arXiv preprint arXiv:****.****},
          year = {2024},
        }
        
</code></pre>
    </div>
  </section>

  <video id="interact" preload muted height="100%" hidden>
    <source src="./static/videos/interact101020.mp4" type="video/mp4">
  </video>

  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="./index.html">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://shunsukesaito.github.io/" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <!-- <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p> -->
            <p>
              This website borrows the template from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>
              and <a href="https://hypernerf.github.io/">HyperNeRF</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
